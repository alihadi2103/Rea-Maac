function reward = sharedReward(x, y, u, u_prev, r)
    % ------------------------
    % NMPC-inspired reward with:
    % - Tracking error cost
    % - Control effort cost
    % - Control rate cost
    % - Quadratic penalty for constraint violation
    % ------------------------

    % === 1. Weight matrices ===
    Q = diag([1, 1, 1]);       % tracking error
    R = diag([0.1, 0.1, 0.1]); % control effort
    S = diag([0.2, 0.2, 0.2]); % rate change penalty

    % === 2. Control bounds (constraints) ===
    umin = [1 1 1];
    umax = [10 10 10];

    % === 3. Cost terms ===
    % Tracking error
    e = y - r;
    tracking_cost = e' * Q * e;

    % Control effort
    control_cost = u' * R * u;

    % Control smoothness
    delta_u = u - u_prev;
    rate_cost = delta_u' * S * delta_u;

    % === 4. Quadratic Penalty for constraints ===
    % Penalize amount by which u exceeds its bounds
    quad_penalty = 0;
    for i = 1:length(u)
        if u(i) < umin(i)
            quad_penalty = quad_penalty + (umin(i) - u(i))^2;
        elseif u(i) > umax(i)
            quad_penalty = quad_penalty + (u(i) - umax(i))^2;
        end
    end

    % Apply a large penalty weight
    P = 100;
    constraint_penalty = P * quad_penalty;

    % === 5. Final reward ===
    total_cost = tracking_cost + control_cost + rate_cost + constraint_penalty;
    reward = -total_cost;
end


    def calculate_reward(self):
        tol = self.precision_tolerance
        err_Cc = abs(self.Cc - self.Cc_sp)/self.Cc_sp
        err_T = abs(self.T - self.T_sp)/self.T_sp
        err_h = abs(self.h - self.h_sp)/self.h_sp

        reward = 0.0
        for err in [err_Cc, err_T, err_h]:
            if err < tol:
                reward += 1000.0 * (1 - err / tol)

        penalty = 0.0
        if self.T < self.T_min:
            penalty += 1000.0 * (self.T_min - self.T)
        elif self.T > self.T_max:
            penalty += 1000.0 * (self.T - self.T_max)

        if self.h < self.h_min:
            penalty += 1000.0 * (self.h_min - self.h)
        elif self.h > self.h_max:
            penalty += 1000.0 * (self.h - self.h_max)

        penalty += 100.0 * (err_Cc + err_T + err_h)

        return reward - penalty



 